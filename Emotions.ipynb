{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1tLgy9Qhp-mU8UDs149CCA-kqApdIbFx7","authorship_tag":"ABX9TyNvF1hWc9DkC0wGXj925Kp7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"],"metadata":{"id":"SVv3GN2Y3YrJ","executionInfo":{"status":"ok","timestamp":1694934329869,"user_tz":-330,"elapsed":400,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_data_dir = '/content/drive/MyDrive/Colab Notebooks/emotions/train'\n","test_data_dir = '/content/drive/MyDrive/Colab Notebooks/emotions/test'\n","img_height, img_width = 48, 48  # Adjust these dimensions as needed\n","batch_size = 32\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    color_mode=\"grayscale\",\n","    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    color_mode=\"grayscale\",\n","    class_mode='categorical'\n",")\n","\n","num_classes = len(train_generator.class_indices)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxM48FE_4rn5","executionInfo":{"status":"ok","timestamp":1694934337671,"user_tz":-330,"elapsed":2819,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}},"outputId":"0b3b604c-29b8-40e1-acf6-1fe28baececd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 28709 images belonging to 7 classes.\n","Found 7178 images belonging to 7 classes.\n"]}]},{"cell_type":"code","source":["model = keras.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n"],"metadata":{"id":"Qax-kkLl4v4F","executionInfo":{"status":"ok","timestamp":1694934735426,"user_tz":-330,"elapsed":3,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n"],"metadata":{"id":"gP7t_mU94xQn","executionInfo":{"status":"ok","timestamp":1694934761370,"user_tz":-330,"elapsed":398,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["epochs = 15  # You can adjust the number of training epochs\n","model.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=test_generator\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxbqZHnt4y5c","executionInfo":{"status":"ok","timestamp":1694935925028,"user_tz":-330,"elapsed":1143837,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}},"outputId":"2220c683-6c20-4744-f5d2-36a8cea93247"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","898/898 [==============================] - 81s 78ms/step - loss: 1.7528 - accuracy: 0.2849 - val_loss: 1.5877 - val_accuracy: 0.3743\n","Epoch 2/15\n","898/898 [==============================] - 84s 93ms/step - loss: 1.5742 - accuracy: 0.3848 - val_loss: 1.4201 - val_accuracy: 0.4561\n","Epoch 3/15\n","898/898 [==============================] - 70s 78ms/step - loss: 1.4684 - accuracy: 0.4310 - val_loss: 1.3828 - val_accuracy: 0.4716\n","Epoch 4/15\n","898/898 [==============================] - 69s 76ms/step - loss: 1.4034 - accuracy: 0.4643 - val_loss: 1.3129 - val_accuracy: 0.4947\n","Epoch 5/15\n","898/898 [==============================] - 69s 77ms/step - loss: 1.3629 - accuracy: 0.4790 - val_loss: 1.2686 - val_accuracy: 0.5167\n","Epoch 6/15\n","898/898 [==============================] - 69s 76ms/step - loss: 1.3265 - accuracy: 0.4970 - val_loss: 1.2278 - val_accuracy: 0.5272\n","Epoch 7/15\n","898/898 [==============================] - 80s 89ms/step - loss: 1.3054 - accuracy: 0.5056 - val_loss: 1.2087 - val_accuracy: 0.5378\n","Epoch 8/15\n","898/898 [==============================] - 69s 77ms/step - loss: 1.2863 - accuracy: 0.5082 - val_loss: 1.2095 - val_accuracy: 0.5322\n","Epoch 9/15\n","898/898 [==============================] - 69s 77ms/step - loss: 1.2696 - accuracy: 0.5164 - val_loss: 1.1796 - val_accuracy: 0.5492\n","Epoch 10/15\n","898/898 [==============================] - 69s 77ms/step - loss: 1.2498 - accuracy: 0.5288 - val_loss: 1.1767 - val_accuracy: 0.5492\n","Epoch 11/15\n","898/898 [==============================] - 101s 113ms/step - loss: 1.2422 - accuracy: 0.5303 - val_loss: 1.1611 - val_accuracy: 0.5539\n","Epoch 12/15\n","898/898 [==============================] - 80s 89ms/step - loss: 1.2238 - accuracy: 0.5375 - val_loss: 1.1964 - val_accuracy: 0.5437\n","Epoch 13/15\n","898/898 [==============================] - 69s 77ms/step - loss: 1.2182 - accuracy: 0.5419 - val_loss: 1.1530 - val_accuracy: 0.5610\n","Epoch 14/15\n","898/898 [==============================] - 69s 76ms/step - loss: 1.1998 - accuracy: 0.5476 - val_loss: 1.1501 - val_accuracy: 0.5663\n","Epoch 15/15\n","898/898 [==============================] - 79s 89ms/step - loss: 1.1933 - accuracy: 0.5481 - val_loss: 1.1357 - val_accuracy: 0.5671\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x786a211414e0>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["model.save('emotion_recognition_model.h5')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsvnlaGk409t","executionInfo":{"status":"ok","timestamp":1694936086666,"user_tz":-330,"elapsed":404,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}},"outputId":"01684a4e-94e3-4cbc-f279-72e388b1b44c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["# Load the saved model\n","loaded_model = keras.models.load_model('emotion_recognition_model.h5')\n","\n","# Load and preprocess the image you want to predict\n","image_path = '/content/drive/MyDrive/Colab Notebooks/emotions/test/im4.png'  # Replace with the path to your image\n","img = keras.preprocessing.image.load_img(\n","    image_path,\n","    target_size=(img_height, img_width),  # Resize the image to match your model's input size\n","    color_mode=\"grayscale\"  # Convert the image to grayscale\n",")\n","img_array = keras.preprocessing.image.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0)  # Expand dimensions for a single image\n","img_array /= 255.0  # Normalize pixel values\n","\n","# Make predictions\n","predictions = loaded_model.predict(img_array)\n","emotion_label = list(train_generator.class_indices.keys())[np.argmax(predictions)]\n","\n","print(f\"The predicted emotion is: {emotion_label}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYoxvidsHsdP","executionInfo":{"status":"ok","timestamp":1694938636112,"user_tz":-330,"elapsed":364,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}},"outputId":"3d8ea359-182c-45ca-c4ed-bfcdeed0eb42"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 68ms/step\n","The predicted emotion is: sad\n"]}]},{"cell_type":"code","source":["# After training the model, add the testing loop\n","\n","# Evaluate the model on the test dataset\n","test_loss, test_accuracy = model.evaluate(test_generator)\n","\n","print(f\"Test loss: {test_loss:.4f}\")\n","print(f\"Test accuracy: {test_accuracy:.4f}\")\n","\n","# You can also add more detailed evaluation metrics if needed\n","# For example, confusion matrix, precision, recall, F1-score, etc.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbwlrnnbL0h7","executionInfo":{"status":"ok","timestamp":1694938138966,"user_tz":-330,"elapsed":12631,"user":{"displayName":"LMT Abel","userId":"06106133588205035334"}},"outputId":"459f3768-1afe-4f23-e68f-2f6af1725b14"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 12s 54ms/step - loss: 1.1357 - accuracy: 0.5671\n","Test loss: 1.1357\n","Test accuracy: 0.5671\n"]}]}]}